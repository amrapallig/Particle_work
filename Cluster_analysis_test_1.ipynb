{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from scipy import stats\n",
    "import time\n",
    "#import numexpr as ne\n",
    "import xarray as xr\n",
    "rEarth = 6371220. #in m ##  get from file variable #f_in.sphere_radius\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#find clusters from initial file\n",
    "# select density layer global data\n",
    "path='/global/cscratch1/sd/garanaik/e3sm_scratch/cori-knl/'\n",
    "den=1028 # input which layer required for filter\n",
    "path_ini='/global/cscratch1/sd/garanaik/data/'\n",
    "data_pt_ini = xr.open_dataset(path_ini+'particles_17011_18to6_16000_dt30min_test_41nb_jan_jul_culled.nc')\n",
    "itemindex = np.where(data_pt_ini.buoyancyParticle[0,:]==den)\n",
    "n=itemindex[0]\n",
    "np1=(n[0]);npm1=(n[-1]) # min and max index for particular buoyancy layer\n",
    "index=np.arange(np1,npm1) #index of all particles belonging to density layer\n",
    "print(index.shape)  #3281952 84y, 1027d,  #3281952 85y, 1027d,\n",
    "\n",
    "data_den_ini=data_pt_ini.sel(nParticles=slice((n[0]),(n[-1])))  \n",
    "\n",
    "\n",
    "llon=data_den_ini.lonParticle[:,:].T\n",
    "llat=data_den_ini.latParticle[:,:].T\n",
    "\n",
    "\n",
    "### cluster grid points # either selected domain or global\n",
    "x,y=np.meshgrid(np.linspace(-90,-20,71),np.linspace(20,50,31)) #cluster center at 1 degree\n",
    "x=np.ravel(np.deg2rad(x)); y=np.ravel(np.deg2rad(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster, circular\n",
    "radius=100000# 100km= 100,000 m\n",
    "import time\n",
    "t1 = time.time()\n",
    "radiustree = radius / (rEarth * np.sin(np.maximum(np.abs(np.min(y)),np.abs(np.max(y)))))  #y is lat, x is long\n",
    "#radiustree = radius / (rEarth * np.sin(np.abs(45)))\n",
    "print(time.time()-t1)\n",
    "print(radiustree)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "allparticles = KDTree(np.vstack((llon[:,0],llat[:,0])).T) #llon[:,0] nparticles,time\n",
    "#print(time.time()-t1)\n",
    "search = KDTree(np.vstack((x,y)).T)                       # x,y cluster centers  defined...\n",
    "#print(time.time()-t1)\n",
    "clusters = search.query_ball_tree(allparticles, radiustree)\n",
    "print(time.time()-t1) \n",
    "\n",
    "\n",
    "Nclusters = x.ravel().shape[0]\n",
    "Nclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lat lon in degree\n",
    "def latlon_from_xyz(xp,yp,zp,r=rEarth):\n",
    "    rinv=1/r \n",
    "    #plat=np.rad2deg(np.arcsin(zp/ np.sqrt(xp**2 + yp**2 + zp**2)))\n",
    "    plat=(np.rad2deg(np.arcsin(zp*rinv)))\n",
    "    plon=(np.rad2deg(np.arctan2(yp, xp)))\n",
    "    return plat, plon\n",
    "\n",
    "def normalized_haversine_formula(phi1, phi2, lam1, lam2,r=rEarth):\n",
    "    \n",
    "    #phi2=np.deg2rad(phi2)\n",
    "    #phi1=np.deg2rad(phi1)\n",
    "    #lam1=np.deg2rad(lam1)\n",
    "    #lam2=np.deg2rad(lam2)\n",
    "    \n",
    "    dphi =( phi2 - phi1)\n",
    "    dlam = (lam2 - lam1)\n",
    "\n",
    "    a = np.sin(dphi/2.0)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlam/2.0)**2\n",
    "    c = r*2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0-a))\n",
    "\n",
    "    return c\n",
    "\n",
    "def spherical_bearing(phi1, phi2, lam1, lam2): \n",
    "     \n",
    "    #phi2=np.deg2rad(phi2)\n",
    "    #phi1=np.deg2rad(phi1)\n",
    "    #lam1=np.deg2rad(lam1)\n",
    "    #lam2=np.deg2rad(lam2)\n",
    "    \n",
    "    dphi = (phi2 - phi1)\n",
    "    dlam = (lam2 - lam1)\n",
    "\n",
    "    return np.arctan2(np.sin(dlam)*np.cos(phi2), np.cos(phi1)*np.sin(phi2) - np.sin(phi1)*np.cos(phi2)*np.cos(dlam)) #}}}\n",
    "\n",
    "def signed_distances(phi1, phi2, lam1, lam2, r=rEarth):  #{{{\n",
    "  \n",
    "    dx = normalized_haversine_formula(phi1, phi1, lam1, lam2,r )\n",
    "    dy = normalized_haversine_formula(phi1, phi2, lam1, lam1,r )\n",
    "    # fix orientation of points\n",
    "    bearing = spherical_bearing(phi1, phi2, lam1, lam2)\n",
    "    # because arctan2 returns results from -pi to pi for bearing, flip values to get right sign\n",
    "    dx -= 2*dx*(bearing < 0)\n",
    "    dy -= 2*dy*(abs(bearing) > np.pi/2.0)\n",
    "    ux = dx/(24.*60.*60.*1)  #m/s\n",
    "    uy = dy/(24.*60.*60.*1)  #m/s\n",
    "   \n",
    "    return ux, uy #}}}  #velocity with dt 1day\n",
    "\n",
    "\n",
    "def bootstrap_ci(data,rep):\n",
    "    n=len(data)\n",
    "    xb = np.random.choice(data, (n, rep), replace=True)\n",
    "    yb = 1/np.arange(1, n+1)[:, None] * np.cumsum(xb, axis=0)\n",
    "    upper, lower = np.percentile(yb, [2.5, 97.5], axis=1)\n",
    "    \n",
    "    \n",
    "    return np.nanmean(upper),np.nanmean(lower),np.nanmean(yb)\n",
    " \n",
    "def cluster_mean_dispersion(plat,plon,r):   #here plat, plon corresponds to that of all \n",
    "                                             #particles in one cluster, one realization, one time step, one layer\n",
    "    clat=np.nanmean(plat)\n",
    "    clon=np.nanmean(plon)\n",
    "    \n",
    "    \n",
    "    dx = normalized_haversine_formula(clat, clat, clon, plon, r)\n",
    "    dy = normalized_haversine_formula(clat, plat, clon, clon, r)\n",
    "    dr = normalized_haversine_formula(clat, plat, clon, plon, r)\n",
    "    \n",
    "    bearing = spherical_bearing(clat, plat, clon, plon)\n",
    "    dx -= 2*dx*(bearing < 0)\n",
    "    dy -= 2*dy*(np.fabs(bearing) > np.pi/2.0)\n",
    "    \n",
    "    dxdx_sum = np.sum(dx*dx)/(len(plat)-1)\n",
    "    dydy_sum = np.sum(dy*dy)/(len(plat)-1)\n",
    "    dxdy_sum = np.sum(dx*dy)/(len(plat)-1)\n",
    "    drdr_sum = np.sum(dr*dr)/(len(plat)-1)\n",
    "    \n",
    "    return clon,clat,dxdx_sum,dydy_sum,dxdy_sum,drdr_sum,len(plat)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all realizations_ all particles\n",
    "#each file corresponds to each realization of 6 month data\n",
    "# this part can be combined to one dataset with all realzations, time, particles.\n",
    "# For now I have kept the realizations fies separate\n",
    "#\n",
    "\n",
    "path='/global/cscratch1/sd/garanaik/e3sm_scratch/cori-knl/'\n",
    "#data_80=xr.open_mfdataset(path+\n",
    "#    r'E3SM_pio2_one-year_test_oRRS18to6v3_pt_16000_4096_4096_256_Ldt30min_41nb_culled_withrestart_from80yrspunup/'\n",
    "#    r'run/analysis_members/*.nc',concat_dim=\"Time\")\n",
    "\n",
    "data=xr.open_mfdataset(path+\n",
    "   r'E3SM_pio2_one-year_test_oRRS18to6v3_pt_16000_4096_4096_256_Ldt30min_41nb_culled_withrestart_from81yr/'\n",
    "   r'run/analysis_members/*.nc',concat_dim=\"Time\",combine='nested')\n",
    "\n",
    "data_den=data.sel(nParticles=slice((n[0]),(n[-1])),Time=slice(0,180)) \n",
    "\n",
    "\n",
    "\n",
    "# test only loading one realization all particle from one density layer\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "plat,plon=latlon_from_xyz(data_den.xParticle.values,data_den.yParticle.values,data_den.zParticle.values)\n",
    "z=data_den.zLevelParticle.values\n",
    "time.time() - t1  \n",
    "\n",
    "\n",
    "\n",
    "plat_r=np.deg2rad(plat)\n",
    "plon_r=np.deg2rad(plon)\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "uvel,vvel   = signed_distances(plat_r[:-1,:], plat_r[1:,:],plon_r[:-1,:], plon_r[1:,:])\n",
    "print(uvel.shape, vvel.shape)\n",
    "time.time() - t1  \n",
    "\n",
    "llon_allt=plon_r[:,:].T\n",
    "llat_allt=plat_r[:,:].T\n",
    "zt=z[:,:].T\n",
    "u_allt=uvel[:,:].T\n",
    "v_allt=vvel[:,:].T\n",
    "\n",
    "Ntime=data_den.xParticle[:,0].shape[0]\n",
    "Nparticles=data_den.xParticle[0,:].shape[0]\n",
    "Nclusters = x.ravel().shape[0]\n",
    "\n",
    "\n",
    "\n",
    "mux      = np.zeros((Ntime,Nclusters))\n",
    "muy      = np.zeros((Ntime,Nclusters))\n",
    "dxdx     = np.zeros((Ntime,Nclusters))\n",
    "dydy     = np.zeros((Ntime,Nclusters))\n",
    "dxdy     = np.zeros((Ntime,Nclusters))\n",
    "drdr     = np.zeros((Ntime,Nclusters))\n",
    "Npart    = np.zeros((Ntime,Nclusters))\n",
    "depth    = np.zeros((Ntime,Nclusters))\n",
    "urms     = np.zeros((Ntime,Nclusters))\n",
    "vrms     = np.zeros((Ntime,Nclusters))\n",
    "umean    = np.zeros((Ntime,Nclusters))\n",
    "vmean    = np.zeros((Ntime,Nclusters))\n",
    "\n",
    "\n",
    "for t in np.arange(Ntime-1):\n",
    "    #print(\"t=\",t)\n",
    "    t1 = time.time()\n",
    "    for c in np.arange(Nclusters):\n",
    "        t2 = time.time()\n",
    "        #print(\"Nclusters=\",c)    \n",
    "        ind=clusters[c]\n",
    "        if (len(ind)>0):\n",
    "            #print(t,c,len(ind))\n",
    "            p_lat=llat_allt[ind,t]\n",
    "            p_lon=llon_allt[ind,t]\n",
    "            p_u=u_allt[ind,t]\n",
    "            p_v=v_allt[ind,t]\n",
    "            #uvel,vvel=signed_distances(llat_allt[ind,t], llat_allt[ind,t+1],llon_allt[ind,t], llat_allt[ind,t+1])\n",
    "            mux[t,c],muy[t,c], dxdx[t,c],dydy[t,c],dxdy[t,c],drdr[t,c], Npart[t,c]=cluster_mean_dispersion(p_lat,p_lon,r=rEarth)\n",
    "            \n",
    "            urms[t,c]=np.nanstd(p_u)\n",
    "            vrms[t,c]=np.nanstd(p_v)\n",
    "            umean[t,c]=np.nanmean(p_u)\n",
    "            vmean[t,c]=np.nanmean(p_v)\n",
    "            depth[t,c]=np.nanmean(zt[ind,t])\n",
    "       \n",
    "        #print(\"time per cluster=\",time.time()-t2)\n",
    "    print(t,\"time per time=\",time.time()-t1)    #time per time= 0.22664380073547363  for 49 cluster\n",
    "    \n",
    "import _pickle as pickle\n",
    "pickle.dump(mux,open(\"./gulfstream/mux_81_1028.p\",\"wb\"))\n",
    "pickle.dump(muy,open(\"./gulfstream/muy_81_1028.p\",\"wb\"))\n",
    "pickle.dump(dxdx,open(\"./gulfstream/dxdx_81_1028.p\",\"wb\"))\n",
    "pickle.dump(dydy,open(\"./gulfstream/dydy_81_1028.p\",\"wb\"))\n",
    "pickle.dump(dxdy,open(\"./gulfstream/dxdy_81_1028.p\",\"wb\"))\n",
    "pickle.dump(drdr,open(\"./gulfstream/drdr_81_1028.p\",\"wb\"))\n",
    "pickle.dump(Npart,open(\"./gulfstream/Npart_81_1028.p\",\"wb\"))\n",
    "pickle.dump(depth,open(\"./gulfstream/depth_81_1028.p\",\"wb\"))\n",
    "pickle.dump(urms,open(\"./gulfstream/urms_81_1028.p\",\"wb\"))\n",
    "pickle.dump(vrms,open(\"./gulfstream/vrms_81_1028.p\",\"wb\"))\n",
    "pickle.dump(umean,open(\"./gulfstream/umean_81_1028.p\",\"wb\"))\n",
    "pickle.dump(vmean,open(\"./gulfstream/vmean_81_1028.p\",\"wb\"))   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
